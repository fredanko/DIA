{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82d7408a",
   "metadata": {},
   "source": [
    "# Task 4: Routing\n",
    "\n",
    "\n",
    "## Reproduction of the task 1 ETL pipeline\n",
    "\n",
    "The first cells only make sure that the file root is set correct and the database connection is build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2419a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path(\"..\").resolve()\n",
    "if repo_root.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, repo_root.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07934147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings(db_host='localhost', db_name='postgres', db_user='postgres', db_password='1234', station_json_path=PosixPath('/Users/rebeccamerdes/Desktop/TU/master/DIA/repo/DIA/DBahn-berlin/repo/station_data.json'), planned_archives_path=PosixPath('/Users/rebeccamerdes/Desktop/TU/master/DIA/repo/DIA/DBahn-berlin/repo/timetables'), changes_archives_path=PosixPath('/Users/rebeccamerdes/Desktop/TU/master/DIA/repo/DIA/DBahn-berlin/repo/timetable_changes'), archive_pattern='*.tar.gz', timezone='Europe/Berlin', match_threshold=0.75, ambiguity_delta=0.02, planned_batch_size=5000, change_batch_size=50000)\n"
     ]
    }
   ],
   "source": [
    "from src.timetable_etl.config import Settings\n",
    "from src.timetable_etl.db import connect\n",
    "\n",
    "settings = Settings.from_env()\n",
    "print(settings)\n",
    "conn = connect(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1d3b4",
   "metadata": {},
   "source": [
    "## Step 0: Deduplication Investigation\n",
    "\n",
    "We just wanted to show the we have investigated the duplicate keys exist in the ``stop_id`` attribute and thus, deduplication is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3680b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files_processed': 135692,\n",
       " 'stop_id_total': 2104080,\n",
       " 'stop_id_unique': 2085472,\n",
       " 'stop_id_duplicates': 18608,\n",
       " 'duplicate_ids': 18608}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.timetable_etl.dedup_invest import count_stop_id_duplicates\n",
    "import os\n",
    "count_stop_id_duplicates(os.path.join(repo_root, \"timetables\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600faa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files_processed': 540668,\n",
       " 'stop_id_total': 1686852,\n",
       " 'stop_id_unique': 1118918,\n",
       " 'stop_id_duplicates': 567934,\n",
       " 'duplicate_ids': 360890}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_stop_id_duplicates(os.path.join(repo_root, \"timetable_changes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1835be",
   "metadata": {},
   "source": [
    "#### Step 1: Build Station Table\n",
    "\n",
    "The imported function reads the ``stations_data.json`` and builds the station dimension table from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8a6578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted station rows: 133\n"
     ]
    }
   ],
   "source": [
    "from src.timetable_etl.stations import import_stationen\n",
    "\n",
    "n = import_stationen(conn, settings.station_json_path)\n",
    "print(\"Upserted station rows:\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd8d98",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4-specific adaptions\n",
    "\n",
    "#### Step 2: Build other Dimension Tables + Fact Table\n",
    "\n",
    "The imported function builds the other dimension tables. Also, it iterates the ``timetables`` directory and inserts the planned values into the stops table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409f463a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'archives_processed': 135692,\n",
       " 'stops_upserted': 2094358,\n",
       " 'unmatched_stations': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.timetable_etl.stops_planned import import_stops_from_archives\n",
    "\n",
    "planned_res = import_stops_from_archives(\n",
    "    conn,\n",
    "    settings.planned_archives_path,\n",
    "    pattern=settings.archive_pattern,\n",
    "    timezone=settings.timezone,\n",
    "    match_threshold=settings.match_threshold,\n",
    "    ambiguity_delta=settings.ambiguity_delta,\n",
    "    batch_size=settings.planned_batch_size,\n",
    ")\n",
    "planned_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6685f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('public', 'stops')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "conn.rollback() \n",
    "\n",
    "query = \"\"\"\n",
    "SELECT table_schema, table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_name = 'stops';\n",
    "\"\"\"\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(query)\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672a63e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop_id',\n",
       " 'eva',\n",
       " 'train_id',\n",
       " 'arrival_pt_id',\n",
       " 'departure_pt_id',\n",
       " 'arrival_ct_id',\n",
       " 'departure_ct_id',\n",
       " 'arrival_clt_id',\n",
       " 'departure_clt_id',\n",
       " 'arrival_cs',\n",
       " 'departure_cs',\n",
       " 'arrival_pp',\n",
       " 'departure_pp',\n",
       " 'arrival_cp',\n",
       " 'departure_cp',\n",
       " 'stop_sequence_index']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.rollback()\n",
    "\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT column_name\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_schema = 'public'\n",
    "          AND table_name = 'stops'\n",
    "        ORDER BY ordinal_position;\n",
    "    \"\"\")\n",
    "    cols = [r[0] for r in cur.fetchall()]\n",
    "\n",
    "cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c914b0",
   "metadata": {},
   "source": [
    "## Step 3: Insert Change Values to Fact Table\n",
    "\n",
    "The imported function iterates the ``timetable_changes`` directory and updates the stops table accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2a0e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'archives_processed': 540668, 'stops_updated': 1132029}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.timetable_etl.stops_changed import process_change_archives\n",
    "\n",
    "changed_res = process_change_archives(\n",
    "    conn,\n",
    "    settings.changes_archives_path,\n",
    "    pattern=settings.archive_pattern,\n",
    "    batch_size=settings.change_batch_size,\n",
    ")\n",
    "changed_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b82b6",
   "metadata": {},
   "source": [
    "### New step: add stop order index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6331c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4857280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.timetable_etl.stop_sequence import ensure_stop_sequence_column\n",
    "\n",
    "conn.rollback()\n",
    "\n",
    "ensure_stop_sequence_column(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e679c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()\n",
    "from src.timetable_etl.stop_sequence import compute_stop_sequence\n",
    "\n",
    "compute_stop_sequence(conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094cb1b9",
   "metadata": {},
   "source": [
    "### 4.1: Shortest route (graph hops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes = stations (identified by eva)\n",
    "# create edges from stop_sequence_index = i -> i+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db6c39",
   "metadata": {},
   "source": [
    "### 4.2: Earliest arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes = stations (eva) and trips\n",
    "# edges = departure edge and arrival edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
