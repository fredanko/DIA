{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def iter_planned_stops_from_archives(\n",
    "    archives_dir: str | Path,\n",
    "    pattern: str = \"*.tar.gz\",\n",
    "    skip_change_files: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Yields tuples:\n",
    "      (source_label, stop_id, ar_pt, dp_pt)\n",
    "\n",
    "    source_label ist z.B. \"<archive_name>::<member_name>\" (für Debug/Beispiele).\n",
    "    \"\"\"\n",
    "    archives_dir = Path(archives_dir)\n",
    "\n",
    "    for archive_path in sorted(archives_dir.glob(pattern)):\n",
    "        try:\n",
    "            with tarfile.open(archive_path, mode=\"r:*\") as tf:\n",
    "                for m in tf.getmembers():\n",
    "                    if not m.isfile() or not m.name.endswith(\".xml\"):\n",
    "                        continue\n",
    "                    if skip_change_files and (m.name.endswith(\"_change.xml\") or m.name.endswith(\"change.xml\")):\n",
    "                        continue\n",
    "\n",
    "                    f = tf.extractfile(m)\n",
    "                    if f is None:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        root = ET.fromstring(f.read())\n",
    "                    except ET.ParseError:\n",
    "                        continue\n",
    "\n",
    "                    source = f\"{archive_path.name}::{m.name}\"\n",
    "\n",
    "                    for s in root.findall(\"./s\"):\n",
    "                        stop_id = s.get(\"id\")\n",
    "                        if not stop_id:\n",
    "                            continue\n",
    "\n",
    "                        ar = s.find(\"ar\")\n",
    "                        dp = s.find(\"dp\")\n",
    "\n",
    "                        ar_pt = (ar.get(\"pt\") if ar is not None else None)\n",
    "                        dp_pt = (dp.get(\"pt\") if dp is not None else None)\n",
    "\n",
    "                        # normalisieren (Whitespace raus, leere Strings -> None)\n",
    "                        if ar_pt is not None:\n",
    "                            ar_pt = ar_pt.strip() or None\n",
    "                        if dp_pt is not None:\n",
    "                            dp_pt = dp_pt.strip() or None\n",
    "\n",
    "                        yield source, stop_id, ar_pt, dp_pt\n",
    "\n",
    "        except (tarfile.TarError, OSError):\n",
    "            continue\n",
    "\n",
    "\n",
    "def check_stop_id_pt_conflicts(\n",
    "    archives_dir: str | Path,\n",
    "    pattern: str = \"*.tar.gz\",\n",
    "    chunk_size: int = 50_000,\n",
    "    max_examples: int = 30,\n",
    "    sqlite_path: str | Path = \"stopid_pt_check.sqlite\",\n",
    "    skip_change_files: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prüft, ob stop_id mehrfach vorkommt und ar_pt/dp_pt verschieden sind.\n",
    "\n",
    "    Returns: summary dict\n",
    "    \"\"\"\n",
    "    sqlite_path = str(sqlite_path)\n",
    "    db = sqlite3.connect(sqlite_path)\n",
    "    db.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "    db.execute(\"PRAGMA synchronous=OFF;\")\n",
    "    db.execute(\"PRAGMA temp_store=MEMORY;\")\n",
    "\n",
    "    db.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS first_seen (\n",
    "            stop_id    TEXT PRIMARY KEY,\n",
    "            ar_pt      TEXT,\n",
    "            dp_pt      TEXT,\n",
    "            first_src  TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "    db.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS conflict_ids (\n",
    "            stop_id TEXT PRIMARY KEY,\n",
    "            kind    TEXT NOT NULL   -- 'enrichment_only' oder 'true_conflict'\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    # TEMP batch table (wird pro chunk neu befüllt)\n",
    "    db.execute(\"\"\"\n",
    "        CREATE TEMP TABLE IF NOT EXISTS batch (\n",
    "            stop_id TEXT,\n",
    "            ar_pt   TEXT,\n",
    "            dp_pt   TEXT,\n",
    "            src     TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "    db.execute(\"CREATE INDEX IF NOT EXISTS batch_stop_id_idx ON batch(stop_id);\")\n",
    "\n",
    "    def is_null(x: str | None) -> bool:\n",
    "        return x is None or x == \"\"\n",
    "\n",
    "    def classify(f_ar, f_dp, n_ar, n_dp) -> str:\n",
    "        # true_conflict, wenn irgendein Feld auf beiden Seiten non-null ist und unterschiedlich\n",
    "        for a, b in ((f_ar, n_ar), (f_dp, n_dp)):\n",
    "            if (not is_null(a)) and (not is_null(b)) and a != b:\n",
    "                return \"true_conflict\"\n",
    "        return \"enrichment_only\"\n",
    "\n",
    "    total_seen = 0\n",
    "    unique_first_seen_inserts = 0\n",
    "    mismatch_rows = 0\n",
    "    new_conflict_stopids = 0\n",
    "    n_true_conflict_stopids = 0\n",
    "\n",
    "    examples = []  # Liste von dicts, bis max_examples\n",
    "\n",
    "    chunk = []\n",
    "\n",
    "    def flush_chunk(rows):\n",
    "        nonlocal unique_first_seen_inserts, mismatch_rows, new_conflict_stopids, n_true_conflict_stopids\n",
    "\n",
    "        if not rows:\n",
    "            return\n",
    "\n",
    "        cur = db.cursor()\n",
    "        cur.execute(\"DELETE FROM batch;\")\n",
    "        cur.executemany(\"INSERT INTO batch (stop_id, ar_pt, dp_pt, src) VALUES (?, ?, ?, ?);\", rows)\n",
    "\n",
    "        # 1) Neue stop_ids “merken”\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO first_seen (stop_id, ar_pt, dp_pt, first_src)\n",
    "            SELECT stop_id, ar_pt, dp_pt, src FROM batch;\n",
    "        \"\"\")\n",
    "        unique_first_seen_inserts += cur.rowcount  # nur die wirklich neu eingefügten stop_ids\n",
    "\n",
    "        # 2) Mismatches finden (gegen die FIRST_SEEN-Werte)\n",
    "        #    Hinweis: first_seen enthält auch frisch inserierte rows -> die matchen nicht als mismatch,\n",
    "        #    weil ar_pt/dp_pt identisch sind.\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT\n",
    "                b.stop_id,\n",
    "                f.ar_pt, f.dp_pt, f.first_src,\n",
    "                b.ar_pt, b.dp_pt, b.src\n",
    "            FROM batch b\n",
    "            JOIN first_seen f ON f.stop_id = b.stop_id\n",
    "            WHERE COALESCE(f.ar_pt, '') != COALESCE(b.ar_pt, '')\n",
    "               OR COALESCE(f.dp_pt, '') != COALESCE(b.dp_pt, '');\n",
    "        \"\"\")\n",
    "        diffs = cur.fetchall()\n",
    "        mismatch_rows += len(diffs)\n",
    "\n",
    "        # 3) Konflikt-StopIDs deduped speichern + klassifizieren\n",
    "        for stop_id, f_ar, f_dp, f_src, n_ar, n_dp, n_src in diffs:\n",
    "            kind = classify(f_ar, f_dp, n_ar, n_dp)\n",
    "\n",
    "            # conflict_ids upsert (wenn schon enrichment_only drin ist und jetzt true_conflict, upgraden)\n",
    "            cur.execute(\"INSERT OR IGNORE INTO conflict_ids (stop_id, kind) VALUES (?, ?);\", (stop_id, kind))\n",
    "            if cur.rowcount == 1:\n",
    "                new_conflict_stopids += 1\n",
    "\n",
    "            if kind == \"true_conflict\":\n",
    "                cur.execute(\"\"\"\n",
    "                    UPDATE conflict_ids\n",
    "                    SET kind = 'true_conflict'\n",
    "                    WHERE stop_id = ? AND kind != 'true_conflict';\n",
    "                \"\"\", (stop_id,))\n",
    "\n",
    "            # Beispiele sammeln (limitiert)\n",
    "            if len(examples) < max_examples:\n",
    "                examples.append({\n",
    "                    \"stop_id\": stop_id,\n",
    "                    \"first\": {\"ar_pt\": f_ar, \"dp_pt\": f_dp, \"src\": f_src},\n",
    "                    \"other\": {\"ar_pt\": n_ar, \"dp_pt\": n_dp, \"src\": n_src},\n",
    "                    \"kind\": kind,\n",
    "                })\n",
    "\n",
    "        db.commit()\n",
    "\n",
    "        # Wie viele true_conflict StopIDs insgesamt?\n",
    "        # (billig genug, das am Ende einmal zu zählen; hier optional)\n",
    "        # -> wir zählen am Ende\n",
    "\n",
    "    for src, stop_id, ar_pt, dp_pt in iter_planned_stops_from_archives(\n",
    "        archives_dir, pattern=pattern, skip_change_files=skip_change_files\n",
    "    ):\n",
    "        total_seen += 1\n",
    "        chunk.append((stop_id, ar_pt, dp_pt, src))\n",
    "        if len(chunk) >= chunk_size:\n",
    "            flush_chunk(chunk)\n",
    "            chunk.clear()\n",
    "\n",
    "    if chunk:\n",
    "        flush_chunk(chunk)\n",
    "        chunk.clear()\n",
    "\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"SELECT COUNT(*) FROM conflict_ids;\")\n",
    "    conflict_stopids = cur.fetchone()[0]\n",
    "    cur.execute(\"SELECT COUNT(*) FROM conflict_ids WHERE kind='true_conflict';\")\n",
    "    true_conflict_stopids = cur.fetchone()[0]\n",
    "    cur.close()\n",
    "    db.close()\n",
    "\n",
    "    return {\n",
    "        \"total_seen_rows_in_xml\": total_seen,\n",
    "        \"unique_stop_ids_first_seen\": unique_first_seen_inserts,\n",
    "        \"mismatch_rows_seen\": mismatch_rows,  # Anzahl der Batch-Zeilen, die abwichen (kann > conflict_stopids sein)\n",
    "        \"conflicting_stop_ids\": conflict_stopids,\n",
    "        \"true_conflict_stop_ids\": true_conflict_stopids,\n",
    "        \"examples\": examples,\n",
    "        \"sqlite_db_path\": sqlite_path,\n",
    "        \"notes\": {\n",
    "            \"kind=enrichment_only\": \"nur NULL<->Wert Unterschiede; kein Feld hat non-null vs non-null und verschieden\",\n",
    "            \"kind=true_conflict\": \"mindestens ein Feld (ar_pt oder dp_pt) ist auf beiden Seiten non-null und unterschiedlich\",\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55354b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Beispiel-Aufruf ---\n",
    "result = check_stop_id_pt_conflicts(\"../timetables\", pattern=\"*.tar.gz\", chunk_size=50_000, max_examples=20)\n",
    "print(result[\"conflicting_stop_ids\"], result[\"true_conflict_stop_ids\"])\n",
    "for ex in result[\"examples\"]:\n",
    "     print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c392c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "FIELDS = [\"ar_pt\", \"dp_pt\", \"ar_ct\", \"dp_ct\", \"ar_clt\", \"dp_clt\"]\n",
    "\n",
    "\n",
    "def iter_stop_attrs_from_archives(\n",
    "    archives_dir: str | Path,\n",
    "    pattern: str = \"*.tar.gz\",\n",
    "    skip_change_files: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Yields:\n",
    "      (source_label, stop_id, ar_pt, dp_pt, ar_ct, dp_ct, ar_clt, dp_clt)\n",
    "\n",
    "    source_label ist \"<archive_name>::<member_name>\" für Debug/Beispiele.\n",
    "    \"\"\"\n",
    "    archives_dir = Path(archives_dir)\n",
    "\n",
    "    for archive_path in sorted(archives_dir.glob(pattern)):\n",
    "        try:\n",
    "            with tarfile.open(archive_path, mode=\"r:*\") as tf:\n",
    "                for m in tf.getmembers():\n",
    "                    if not m.isfile() or not m.name.endswith(\".xml\"):\n",
    "                        continue\n",
    "                    if skip_change_files and (m.name.endswith(\"_change.xml\") or m.name.endswith(\"change.xml\")):\n",
    "                        continue\n",
    "\n",
    "                    f = tf.extractfile(m)\n",
    "                    if f is None:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        root = ET.fromstring(f.read())\n",
    "                    except ET.ParseError:\n",
    "                        continue\n",
    "\n",
    "                    source = f\"{archive_path.name}::{m.name}\"\n",
    "\n",
    "                    for s in root.findall(\"./s\"):\n",
    "                        stop_id = s.get(\"id\")\n",
    "                        if not stop_id:\n",
    "                            continue\n",
    "\n",
    "                        ar = s.find(\"ar\")\n",
    "                        dp = s.find(\"dp\")\n",
    "\n",
    "                        def g(node, attr):\n",
    "                            if node is None:\n",
    "                                return None\n",
    "                            v = node.get(attr)\n",
    "                            if v is None:\n",
    "                                return None\n",
    "                            v = v.strip()\n",
    "                            return v or None\n",
    "\n",
    "                        ar_pt  = g(ar, \"pt\")\n",
    "                        dp_pt  = g(dp, \"pt\")\n",
    "                        ar_ct  = g(ar, \"ct\")\n",
    "                        dp_ct  = g(dp, \"ct\")\n",
    "                        ar_clt = g(ar, \"clt\")\n",
    "                        dp_clt = g(dp, \"clt\")\n",
    "\n",
    "                        yield source, stop_id, ar_pt, dp_pt, ar_ct, dp_ct, ar_clt, dp_clt\n",
    "\n",
    "        except (tarfile.TarError, OSError):\n",
    "            continue\n",
    "\n",
    "\n",
    "def check_stop_id_timeattr_conflicts(\n",
    "    archives_dir: str | Path,\n",
    "    pattern: str = \"*.tar.gz\",\n",
    "    chunk_size: int = 50_000,\n",
    "    max_examples: int = 30,\n",
    "    sqlite_path: str | Path = \"stopid_timeattr_check.sqlite\",\n",
    "    reset_sqlite: bool = True,\n",
    "    skip_change_files: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Prüft für stop_id Konflikte in:\n",
    "      ar/@pt, dp/@pt, ar/@ct, dp/@ct, ar/@clt, dp/@clt\n",
    "\n",
    "    Konflikt = beide Werte non-null und verschieden.\n",
    "    Enrichment = nur NULL<->Wert (kein echter Widerspruch).\n",
    "\n",
    "    Returns: summary dict inkl. Counts pro Feld + Beispiele.\n",
    "    \"\"\"\n",
    "    sqlite_path = Path(sqlite_path)\n",
    "    if reset_sqlite and sqlite_path.exists():\n",
    "        sqlite_path.unlink()\n",
    "\n",
    "    db = sqlite3.connect(str(sqlite_path))\n",
    "    db.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "    db.execute(\"PRAGMA synchronous=OFF;\")\n",
    "    db.execute(\"PRAGMA temp_store=MEMORY;\")\n",
    "\n",
    "    db.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS first_seen (\n",
    "            stop_id    TEXT PRIMARY KEY,\n",
    "            ar_pt      TEXT, dp_pt      TEXT,\n",
    "            ar_ct      TEXT, dp_ct      TEXT,\n",
    "            ar_clt     TEXT, dp_clt     TEXT,\n",
    "            first_src  TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    # stop_id -> Flags pro Feld (conflict/enrichment)\n",
    "    db.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS flags (\n",
    "            stop_id TEXT PRIMARY KEY,\n",
    "            ar_pt_conflict  INTEGER NOT NULL DEFAULT 0,\n",
    "            dp_pt_conflict  INTEGER NOT NULL DEFAULT 0,\n",
    "            ar_ct_conflict  INTEGER NOT NULL DEFAULT 0,\n",
    "            dp_ct_conflict  INTEGER NOT NULL DEFAULT 0,\n",
    "            ar_clt_conflict INTEGER NOT NULL DEFAULT 0,\n",
    "            dp_clt_conflict INTEGER NOT NULL DEFAULT 0,\n",
    "\n",
    "            ar_pt_enrich  INTEGER NOT NULL DEFAULT 0,\n",
    "            dp_pt_enrich  INTEGER NOT NULL DEFAULT 0,\n",
    "            ar_ct_enrich  INTEGER NOT NULL DEFAULT 0,\n",
    "            dp_ct_enrich  INTEGER NOT NULL DEFAULT 0,\n",
    "            ar_clt_enrich INTEGER NOT NULL DEFAULT 0,\n",
    "            dp_clt_enrich INTEGER NOT NULL DEFAULT 0\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    db.execute(\"\"\"\n",
    "        CREATE TEMP TABLE IF NOT EXISTS batch (\n",
    "            stop_id TEXT,\n",
    "            ar_pt   TEXT, dp_pt   TEXT,\n",
    "            ar_ct   TEXT, dp_ct   TEXT,\n",
    "            ar_clt  TEXT, dp_clt  TEXT,\n",
    "            src     TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "    db.execute(\"CREATE INDEX IF NOT EXISTS batch_stop_id_idx ON batch(stop_id);\")\n",
    "\n",
    "    def is_null(x: str | None) -> bool:\n",
    "        return x is None or x == \"\"\n",
    "\n",
    "    def differs(a: str | None, b: str | None) -> bool:\n",
    "        return (a or \"\") != (b or \"\")\n",
    "\n",
    "    total_seen = 0\n",
    "    mismatch_rows = 0\n",
    "    examples: list[dict] = []\n",
    "\n",
    "    chunk = []\n",
    "\n",
    "    def flush_chunk(rows):\n",
    "        nonlocal mismatch_rows\n",
    "\n",
    "        if not rows:\n",
    "            return\n",
    "\n",
    "        cur = db.cursor()\n",
    "        cur.execute(\"DELETE FROM batch;\")\n",
    "        cur.executemany(\n",
    "            \"\"\"\n",
    "            INSERT INTO batch (stop_id, ar_pt, dp_pt, ar_ct, dp_ct, ar_clt, dp_clt, src)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?);\n",
    "            \"\"\",\n",
    "            rows,\n",
    "        )\n",
    "\n",
    "        # first_seen füllen (nur wenn stop_id neu)\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO first_seen\n",
    "                (stop_id, ar_pt, dp_pt, ar_ct, dp_ct, ar_clt, dp_clt, first_src)\n",
    "            SELECT stop_id, ar_pt, dp_pt, ar_ct, dp_ct, ar_clt, dp_clt, src\n",
    "            FROM batch;\n",
    "        \"\"\")\n",
    "\n",
    "        # Diffs gegen first_seen\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT\n",
    "                b.stop_id,\n",
    "                f.ar_pt, f.dp_pt, f.ar_ct, f.dp_ct, f.ar_clt, f.dp_clt, f.first_src,\n",
    "                b.ar_pt, b.dp_pt, b.ar_ct, b.dp_ct, b.ar_clt, b.dp_clt, b.src\n",
    "            FROM batch b\n",
    "            JOIN first_seen f ON f.stop_id = b.stop_id\n",
    "            WHERE COALESCE(f.ar_pt,'')  != COALESCE(b.ar_pt,'')\n",
    "               OR COALESCE(f.dp_pt,'')  != COALESCE(b.dp_pt,'')\n",
    "               OR COALESCE(f.ar_ct,'')  != COALESCE(b.ar_ct,'')\n",
    "               OR COALESCE(f.dp_ct,'')  != COALESCE(b.dp_ct,'')\n",
    "               OR COALESCE(f.ar_clt,'') != COALESCE(b.ar_clt,'')\n",
    "               OR COALESCE(f.dp_clt,'') != COALESCE(b.dp_clt,'');\n",
    "        \"\"\")\n",
    "        diffs = cur.fetchall()\n",
    "        mismatch_rows += len(diffs)\n",
    "\n",
    "        # flags updaten\n",
    "        for row in diffs:\n",
    "            (\n",
    "                stop_id,\n",
    "                f_ar_pt, f_dp_pt, f_ar_ct, f_dp_ct, f_ar_clt, f_dp_clt, f_src,\n",
    "                n_ar_pt, n_dp_pt, n_ar_ct, n_dp_ct, n_ar_clt, n_dp_clt, n_src\n",
    "            ) = row\n",
    "\n",
    "            first_vals = {\n",
    "                \"ar_pt\": f_ar_pt, \"dp_pt\": f_dp_pt,\n",
    "                \"ar_ct\": f_ar_ct, \"dp_ct\": f_dp_ct,\n",
    "                \"ar_clt\": f_ar_clt, \"dp_clt\": f_dp_clt,\n",
    "            }\n",
    "            new_vals = {\n",
    "                \"ar_pt\": n_ar_pt, \"dp_pt\": n_dp_pt,\n",
    "                \"ar_ct\": n_ar_ct, \"dp_ct\": n_dp_ct,\n",
    "                \"ar_clt\": n_ar_clt, \"dp_clt\": n_dp_clt,\n",
    "            }\n",
    "\n",
    "            # ensure flags row exists\n",
    "            cur.execute(\"INSERT OR IGNORE INTO flags (stop_id) VALUES (?);\", (stop_id,))\n",
    "\n",
    "            diff_summary = {}\n",
    "            for fld in FIELDS:\n",
    "                a = first_vals[fld]\n",
    "                b = new_vals[fld]\n",
    "                if not differs(a, b):\n",
    "                    continue\n",
    "\n",
    "                if (not is_null(a)) and (not is_null(b)) and a != b:\n",
    "                    # echter Konflikt\n",
    "                    cur.execute(f\"UPDATE flags SET {fld}_conflict = 1 WHERE stop_id = ?;\", (stop_id,))\n",
    "                    diff_summary[fld] = {\"kind\": \"conflict\", \"first\": a, \"other\": b}\n",
    "                else:\n",
    "                    # nur NULL<->Wert\n",
    "                    cur.execute(f\"UPDATE flags SET {fld}_enrich = 1 WHERE stop_id = ?;\", (stop_id,))\n",
    "                    diff_summary[fld] = {\"kind\": \"enrich\", \"first\": a, \"other\": b}\n",
    "\n",
    "            if diff_summary and len(examples) < max_examples:\n",
    "                examples.append({\n",
    "                    \"stop_id\": stop_id,\n",
    "                    \"first_src\": f_src,\n",
    "                    \"other_src\": n_src,\n",
    "                    \"diffs\": diff_summary,\n",
    "                })\n",
    "\n",
    "        db.commit()\n",
    "        cur.close()\n",
    "\n",
    "    for src, stop_id, ar_pt, dp_pt, ar_ct, dp_ct, ar_clt, dp_clt in iter_stop_attrs_from_archives(\n",
    "        archives_dir, pattern=pattern, skip_change_files=skip_change_files\n",
    "    ):\n",
    "        total_seen += 1\n",
    "        chunk.append((stop_id, ar_pt, dp_pt, ar_ct, dp_ct, ar_clt, dp_clt, src))\n",
    "        if len(chunk) >= chunk_size:\n",
    "            flush_chunk(chunk)\n",
    "            chunk.clear()\n",
    "\n",
    "    if chunk:\n",
    "        flush_chunk(chunk)\n",
    "        chunk.clear()\n",
    "\n",
    "    # Counts pro Feld\n",
    "    cur = db.cursor()\n",
    "    counts = {}\n",
    "    for fld in FIELDS:\n",
    "        cur.execute(f\"SELECT SUM({fld}_conflict) FROM flags;\")\n",
    "        counts[f\"{fld}_conflict_stop_ids\"] = int(cur.fetchone()[0] or 0)\n",
    "        cur.execute(f\"SELECT SUM({fld}_enrich) FROM flags;\")\n",
    "        counts[f\"{fld}_enrichment_stop_ids\"] = int(cur.fetchone()[0] or 0)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM flags\n",
    "        WHERE ar_pt_conflict=1 OR dp_pt_conflict=1\n",
    "           OR ar_ct_conflict=1 OR dp_ct_conflict=1\n",
    "           OR ar_clt_conflict=1 OR dp_clt_conflict=1;\n",
    "    \"\"\")\n",
    "    any_conflict_stop_ids = int(cur.fetchone()[0] or 0)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT COUNT(*) FROM flags\n",
    "        WHERE ar_pt_enrich=1 OR dp_pt_enrich=1\n",
    "           OR ar_ct_enrich=1 OR dp_ct_enrich=1\n",
    "           OR ar_clt_enrich=1 OR dp_clt_enrich=1;\n",
    "    \"\"\")\n",
    "    any_enrichment_stop_ids = int(cur.fetchone()[0] or 0)\n",
    "\n",
    "    cur.close()\n",
    "    db.close()\n",
    "\n",
    "    return {\n",
    "        \"total_seen_rows_in_xml\": total_seen,\n",
    "        \"mismatch_rows_seen\": mismatch_rows,\n",
    "        \"any_conflict_stop_ids\": any_conflict_stop_ids,\n",
    "        \"any_enrichment_stop_ids\": any_enrichment_stop_ids,\n",
    "        \"per_field\": counts,\n",
    "        \"examples\": examples,\n",
    "        \"sqlite_db_path\": str(sqlite_path),\n",
    "        \"notes\": {\n",
    "            \"conflict\": \"beide Werte non-null und verschieden (echter Widerspruch)\",\n",
    "            \"enrichment\": \"nur NULL<->Wert (kein Widerspruch, nur 'mehr Info')\",\n",
    "            \"skip_change_files\": \"Für ct/clt meist False setzen, sonst werden *_change.xml ignoriert.\",\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbe6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any_conflict_stop_ids: 0\n",
      "any_enrichment_stop_ids: 0\n",
      "{'ar_pt_conflict_stop_ids': 0, 'ar_pt_enrichment_stop_ids': 0, 'dp_pt_conflict_stop_ids': 0, 'dp_pt_enrichment_stop_ids': 0, 'ar_ct_conflict_stop_ids': 0, 'ar_ct_enrichment_stop_ids': 0, 'dp_ct_conflict_stop_ids': 0, 'dp_ct_enrichment_stop_ids': 0, 'ar_clt_conflict_stop_ids': 0, 'ar_clt_enrichment_stop_ids': 0, 'dp_clt_conflict_stop_ids': 0, 'dp_clt_enrichment_stop_ids': 0}\n"
     ]
    }
   ],
   "source": [
    "# --- Beispiel-Aufruf ---\n",
    "result = check_stop_id_timeattr_conflicts(\n",
    "    \"../timetables\",\n",
    "    pattern=\"*.tar.gz\",\n",
    "    chunk_size=50_000,\n",
    "    max_examples=20,\n",
    "    skip_change_files=False,  # wichtig für ct/clt\n",
    ")\n",
    "print(\"any_conflict_stop_ids:\", result[\"any_conflict_stop_ids\"])\n",
    "print(\"any_enrichment_stop_ids:\", result[\"any_enrichment_stop_ids\"])\n",
    "print(result[\"per_field\"])\n",
    "for ex in result[\"examples\"]:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0decc738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any_conflict_stop_ids: 149974\n",
      "any_enrichment_stop_ids: 161297\n",
      "{'ar_pt_conflict_stop_ids': 0, 'ar_pt_enrichment_stop_ids': 5768, 'dp_pt_conflict_stop_ids': 0, 'dp_pt_enrichment_stop_ids': 4737, 'ar_ct_conflict_stop_ids': 131065, 'ar_ct_enrichment_stop_ids': 137838, 'dp_ct_conflict_stop_ids': 123387, 'dp_ct_enrichment_stop_ids': 137766, 'ar_clt_conflict_stop_ids': 13, 'ar_clt_enrichment_stop_ids': 21223, 'dp_clt_conflict_stop_ids': 14, 'dp_clt_enrichment_stop_ids': 21352}\n",
      "{'stop_id': '4396219182070181868-2509021612-16', 'first_src': '250902_250909.tar.gz::2509021600/alexanderplatz_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/alexanderplatz_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021807', 'other': '2509021806'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021808', 'other': '2509021807'}}}\n",
      "{'stop_id': '231917818137011807-2509021414-20', 'first_src': '250902_250909.tar.gz::2509021600/alexanderplatz_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/alexanderplatz_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021630', 'other': '2509021625'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021631', 'other': '2509021626'}}}\n",
      "{'stop_id': '2297658875142437576-2509021601-12', 'first_src': '250902_250909.tar.gz::2509021600/alexanderplatz_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/alexanderplatz_change.xml', 'diffs': {'dp_ct': {'kind': 'conflict', 'first': '2509021657', 'other': '2509021656'}}}\n",
      "{'stop_id': '-1869923735659366107-2509021526-12', 'first_src': '250902_250909.tar.gz::2509021600/alexanderplatz_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/alexanderplatz_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021638', 'other': '2509021633'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021639', 'other': '2509021634'}}}\n",
      "{'stop_id': '-1925280481280049261-2509021614-4', 'first_src': '250902_250909.tar.gz::2509021600/alexanderplatz_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/alexanderplatz_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021642', 'other': '2509021641'}}}\n",
      "{'stop_id': '6927368918735974093-2509021626-12', 'first_src': '250902_250909.tar.gz::2509021600/alexanderplatz_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/alexanderplatz_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021735', 'other': '2509021733'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021736', 'other': '2509021734'}}}\n",
      "{'stop_id': '6466087082911955334-2509021545-20', 'first_src': '250902_250909.tar.gz::2509021600/alt-reinickendorf_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/alt-reinickendorf_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021632', 'other': '2509021630'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021632', 'other': '2509021631'}}}\n",
      "{'stop_id': '3928600713466255753-2509021608-10', 'first_src': '250902_250909.tar.gz::2509021600/altglienicke_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/altglienicke_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021636', 'other': '2509021634'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021636', 'other': '2509021634'}}}\n",
      "{'stop_id': '-1267720593014128115-2509021624-4', 'first_src': '250902_250909.tar.gz::2509021600/baumschulenweg_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/baumschulenweg_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021634', 'other': '2509021631'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021635', 'other': '2509021633'}}}\n",
      "{'stop_id': '5651852307817564121-2509021537-22', 'first_src': '250902_250909.tar.gz::2509021600/baumschulenweg_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/baumschulenweg_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021628', 'other': '2509021627'}}}\n",
      "{'stop_id': '8528609145838060424-2509021617-6', 'first_src': '250902_250909.tar.gz::2509021600/bellevue_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/bellevue_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021629', 'other': '2509021627'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021629', 'other': '2509021628'}}}\n",
      "{'stop_id': '3928600713466255753-2509021608-9', 'first_src': '250902_250909.tar.gz::2509021600/berlin-adlershof_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-adlershof_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021632', 'other': '2509021629'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021632', 'other': '2509021630'}}}\n",
      "{'stop_id': '-4845604826762075201-2509021609-6', 'first_src': '250902_250909.tar.gz::2509021600/berlin-adlershof_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-adlershof_change.xml', 'diffs': {'dp_ct': {'kind': 'conflict', 'first': '2509021628', 'other': '2509021627'}}}\n",
      "{'stop_id': '4396219182070181868-2509021612-12', 'first_src': '250902_250909.tar.gz::2509021600/berlin-charlottenburg_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-charlottenburg_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021750', 'other': '2509021749'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021751', 'other': '2509021750'}}}\n",
      "{'stop_id': '7388196342613390136-2509021436-13', 'first_src': '250902_250909.tar.gz::2509021600/berlin-charlottenburg_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-charlottenburg_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021638', 'other': '2509021634'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021639', 'other': '2509021635'}}}\n",
      "{'stop_id': '1415115277631270144-2509021527-26', 'first_src': '250902_250909.tar.gz::2509021600/berlin-friedrichshagen_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-friedrichshagen_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021627', 'other': '2509021628'}}}\n",
      "{'stop_id': '4396219182070181868-2509021612-15', 'first_src': '250902_250909.tar.gz::2509021600/berlin-friedrichstra_e_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-friedrichstra_e_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021803', 'other': '2509021802'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021804', 'other': '2509021803'}}}\n",
      "{'stop_id': '231917818137011807-2509021414-21', 'first_src': '250902_250909.tar.gz::2509021600/berlin-friedrichstra_e_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-friedrichstra_e_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021631', 'other': '2509021628'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021634', 'other': '2509021629'}}}\n",
      "{'stop_id': '-1869923735659366107-2509021526-13', 'first_src': '250902_250909.tar.gz::2509021600/berlin-friedrichstra_e_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-friedrichstra_e_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021641', 'other': '2509021636'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021642', 'other': '2509021637'}}}\n",
      "{'stop_id': '6927368918735974093-2509021626-13', 'first_src': '250902_250909.tar.gz::2509021600/berlin-friedrichstra_e_change.xml', 'other_src': '250902_250909.tar.gz::2509021615/berlin-friedrichstra_e_change.xml', 'diffs': {'ar_ct': {'kind': 'conflict', 'first': '2509021738', 'other': '2509021736'}, 'dp_ct': {'kind': 'conflict', 'first': '2509021739', 'other': '2509021737'}}}\n"
     ]
    }
   ],
   "source": [
    "# --- Beispiel-Aufruf ---\n",
    "result = check_stop_id_timeattr_conflicts(\n",
    "    \"../timetable_changes\",\n",
    "    pattern=\"*.tar.gz\",\n",
    "    chunk_size=50_000,\n",
    "    max_examples=20,\n",
    "    skip_change_files=False,  # wichtig für ct/clt\n",
    ")\n",
    "print(\"any_conflict_stop_ids:\", result[\"any_conflict_stop_ids\"])\n",
    "print(\"any_enrichment_stop_ids:\", result[\"any_enrichment_stop_ids\"])\n",
    "print(result[\"per_field\"])\n",
    "for ex in result[\"examples\"]:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fec303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
