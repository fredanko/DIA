{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "  change files processed: 540668\n",
      "  stop updates staged:    1346664\n",
      "  rows updated (SQL):     953744\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path, PurePosixPath\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "try:\n",
    "    from psycopg2.extras import execute_values\n",
    "except Exception:\n",
    "    execute_values = None\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Schema-Änderung (einmalig)\n",
    "# ----------------------------\n",
    "def ensure_actual_columns(conn):\n",
    "    # Spalten idempotent anlegen\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            ALTER TABLE public.stops\n",
    "                ADD COLUMN IF NOT EXISTS actual_arrival   timestamptz,\n",
    "                ADD COLUMN IF NOT EXISTS actual_departure timestamptz,\n",
    "                ADD COLUMN IF NOT EXISTS cancelled_arrival   timestamptz,\n",
    "                ADD COLUMN IF NOT EXISTS cancelled_departure timestamptz,\n",
    "                ADD COLUMN IF NOT EXISTS arrival_cs   text,\n",
    "                ADD COLUMN IF NOT EXISTS departure_cs text;\n",
    "        \"\"\")\n",
    "        # Constraint idempotent hinzufügen (ohne IF NOT EXISTS, da nicht überall unterstützt)\n",
    "        cur.execute(\"\"\"\n",
    "            DO $$\n",
    "            BEGIN\n",
    "                ALTER TABLE public.stops\n",
    "                    ADD CONSTRAINT stops_cs_check\n",
    "                    CHECK (\n",
    "                        (arrival_cs   IS NULL OR arrival_cs   IN ('a','p','c')) AND\n",
    "                        (departure_cs IS NULL OR departure_cs IN ('a','p','c'))\n",
    "                    );\n",
    "            EXCEPTION\n",
    "                WHEN duplicate_object THEN\n",
    "                    NULL;\n",
    "            END $$;\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Helpers: ct/clt -> datetime + cs + snapshot_ts aus Member-Pfad\n",
    "# ----------------------------\n",
    "BERLIN_TZ = ZoneInfo(\"Europe/Berlin\")\n",
    "\n",
    "def parse_db_ct(ct: str | None):\n",
    "    \"\"\"Format: YYMMDDHHMM -> aware datetime (Europe/Berlin)\"\"\"\n",
    "    if not ct:\n",
    "        return None\n",
    "    ct = ct.strip()\n",
    "    if len(ct) != 10 or not ct.isdigit():\n",
    "        return None\n",
    "    dt = datetime.strptime(ct, \"%y%m%d%H%M\")\n",
    "    return dt.replace(tzinfo=BERLIN_TZ)\n",
    "\n",
    "def parse_cs(x: str | None) -> str | None:\n",
    "    if not x:\n",
    "        return None\n",
    "    x = x.strip().lower()\n",
    "    return x if x in {\"a\", \"p\", \"c\"} else None\n",
    "\n",
    "def snapshot_ts_from_member_name(xml_member_name: str) -> datetime | None:\n",
    "    \"\"\"\n",
    "    Erwartet Member-Pfade wie: \"2510011345/...._change.xml\"\n",
    "    -> snapshot_ts = 2025-10-01 13:45 Europe/Berlin\n",
    "    \"\"\"\n",
    "    p = PurePosixPath(xml_member_name)\n",
    "    if not p.parts:\n",
    "        return None\n",
    "    head = p.parts[0]\n",
    "    if len(head) == 10 and head.isdigit():\n",
    "        dt = datetime.strptime(head, \"%y%m%d%H%M\")\n",
    "        return dt.replace(tzinfo=BERLIN_TZ)\n",
    "    return None\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Batch-Update via TEMP staging table + TEMP latest_snapshot\n",
    "# ----------------------------\n",
    "def init_stage_tables(conn):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TEMP TABLE IF NOT EXISTS _stops_change_stage (\n",
    "                stop_id             text PRIMARY KEY,\n",
    "                snapshot_ts         timestamptz NULL,\n",
    "                actual_arrival      timestamptz NULL,\n",
    "                actual_departure    timestamptz NULL,\n",
    "                cancelled_arrival   timestamptz NULL,\n",
    "                cancelled_departure timestamptz NULL,\n",
    "                arrival_cs          text NULL,\n",
    "                departure_cs        text NULL\n",
    "            );\n",
    "        \"\"\")\n",
    "        # bleibt über alle Batches erhalten (pro Connection)\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TEMP TABLE IF NOT EXISTS _stops_latest_snapshot (\n",
    "                stop_id     text PRIMARY KEY,\n",
    "                snapshot_ts timestamptz NOT NULL\n",
    "            );\n",
    "        \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def apply_batch(conn, batch_rows):\n",
    "    \"\"\"\n",
    "    batch_rows:\n",
    "      [(stop_id, snapshot_ts,\n",
    "        actual_arrival, actual_departure,\n",
    "        cancelled_arrival, cancelled_departure,\n",
    "        arrival_cs, departure_cs), ...]\n",
    "    \"\"\"\n",
    "    if not batch_rows:\n",
    "        return 0\n",
    "\n",
    "    init_stage_tables(conn)\n",
    "\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"TRUNCATE TABLE _stops_change_stage;\")\n",
    "\n",
    "        if execute_values is not None:\n",
    "            execute_values(\n",
    "                cur,\n",
    "                \"\"\"\n",
    "                INSERT INTO _stops_change_stage (\n",
    "                    stop_id, snapshot_ts,\n",
    "                    actual_arrival, actual_departure,\n",
    "                    cancelled_arrival, cancelled_departure,\n",
    "                    arrival_cs, departure_cs\n",
    "                )\n",
    "                VALUES %s\n",
    "                \"\"\",\n",
    "                batch_rows,\n",
    "                page_size=10_000\n",
    "            )\n",
    "        else:\n",
    "            cur.executemany(\n",
    "                \"\"\"\n",
    "                INSERT INTO _stops_change_stage (\n",
    "                    stop_id, snapshot_ts,\n",
    "                    actual_arrival, actual_departure,\n",
    "                    cancelled_arrival, cancelled_departure,\n",
    "                    arrival_cs, departure_cs\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                \"\"\",\n",
    "                batch_rows\n",
    "            )\n",
    "\n",
    "        # 1) latest snapshot pro stop_id updaten (global über alle Batches)\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO _stops_latest_snapshot (stop_id, snapshot_ts)\n",
    "            SELECT\n",
    "                stop_id,\n",
    "                COALESCE(snapshot_ts, '-infinity'::timestamptz)\n",
    "            FROM _stops_change_stage\n",
    "            ON CONFLICT (stop_id) DO UPDATE\n",
    "            SET snapshot_ts = GREATEST(_stops_latest_snapshot.snapshot_ts, EXCLUDED.snapshot_ts);\n",
    "        \"\"\")\n",
    "\n",
    "        # 2) Nur anwenden, wenn dieser Stage-Datensatz zum aktuell neuesten Snapshot gehört\n",
    "        cur.execute(\"\"\"\n",
    "            UPDATE public.stops s\n",
    "            SET\n",
    "                actual_arrival      = COALESCE(st.actual_arrival,      s.actual_arrival),\n",
    "                actual_departure    = COALESCE(st.actual_departure,    s.actual_departure),\n",
    "                cancelled_arrival   = COALESCE(st.cancelled_arrival,   s.cancelled_arrival),\n",
    "                cancelled_departure = COALESCE(st.cancelled_departure, s.cancelled_departure),\n",
    "                arrival_cs          = COALESCE(st.arrival_cs,          s.arrival_cs),\n",
    "                departure_cs        = COALESCE(st.departure_cs,        s.departure_cs)\n",
    "            FROM _stops_change_stage st\n",
    "            JOIN _stops_latest_snapshot ls\n",
    "              ON ls.stop_id = st.stop_id\n",
    "            WHERE s.stop_id = st.stop_id\n",
    "              AND COALESCE(st.snapshot_ts, '-infinity'::timestamptz) = ls.snapshot_ts;\n",
    "        \"\"\")\n",
    "        updated = cur.rowcount\n",
    "\n",
    "    conn.commit()\n",
    "    return updated\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Main: Changes einlesen & updaten\n",
    "# ----------------------------\n",
    "def process_change_archives(conn, archives_dir: str | Path, pattern: str = \"*.tar.gz\", batch_size: int = 50_000):\n",
    "    ensure_actual_columns(conn)\n",
    "    init_stage_tables(conn)\n",
    "\n",
    "    # Dedupe im Batch: max(snapshot_ts) wins; bei Gleichstand: non-null merge (inkl. cs)\n",
    "    batch: dict[str, tuple] = {}\n",
    "\n",
    "    def snap_key(dt: datetime | None) -> datetime:\n",
    "        return dt if dt is not None else datetime.min.replace(tzinfo=BERLIN_TZ)\n",
    "\n",
    "    n_change_files = 0\n",
    "    n_s_nodes = 0\n",
    "    n_updates = 0\n",
    "\n",
    "    for archive_path, xml_member_name, root in iter_xml_roots(archives_dir, pattern=pattern):\n",
    "        if not (xml_member_name.endswith(\"_change.xml\") or xml_member_name.endswith(\"change.xml\")):\n",
    "            continue\n",
    "\n",
    "        n_change_files += 1\n",
    "        snapshot_ts = snapshot_ts_from_member_name(xml_member_name)\n",
    "\n",
    "        for s in root.findall(\"./s\"):\n",
    "            stop_id = s.get(\"id\")\n",
    "            if not stop_id:\n",
    "                continue\n",
    "\n",
    "            ar = s.find(\"ar\")\n",
    "            dp = s.find(\"dp\")\n",
    "\n",
    "            ar_ct  = ar.get(\"ct\")  if ar is not None else None\n",
    "            dp_ct  = dp.get(\"ct\")  if dp is not None else None\n",
    "            ar_clt = ar.get(\"clt\") if ar is not None else None\n",
    "            dp_clt = dp.get(\"clt\") if dp is not None else None\n",
    "\n",
    "            ar_cs = parse_cs(ar.get(\"cs\") if ar is not None else None)\n",
    "            dp_cs = parse_cs(dp.get(\"cs\") if dp is not None else None)\n",
    "\n",
    "            actual_arrival      = parse_db_ct(ar_ct)\n",
    "            actual_departure    = parse_db_ct(dp_ct)\n",
    "            cancelled_arrival   = parse_db_ct(ar_clt)\n",
    "            cancelled_departure = parse_db_ct(dp_clt)\n",
    "\n",
    "            # Wenn wirklich gar nichts da ist, skip (cs zählt als \"Daten vorhanden\")\n",
    "            if (\n",
    "                actual_arrival is None and actual_departure is None\n",
    "                and cancelled_arrival is None and cancelled_departure is None\n",
    "                and ar_cs is None and dp_cs is None\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            new_row = (\n",
    "                stop_id, snapshot_ts,\n",
    "                actual_arrival, actual_departure,\n",
    "                cancelled_arrival, cancelled_departure,\n",
    "                ar_cs, dp_cs\n",
    "            )\n",
    "\n",
    "            old = batch.get(stop_id)\n",
    "            if old is None:\n",
    "                batch[stop_id] = new_row\n",
    "            else:\n",
    "                # FIX: korrekt 8 Werte entpacken\n",
    "                _, old_snap, old_aa, old_ad, old_ca, old_cd, old_ar_cs, old_dp_cs = old\n",
    "\n",
    "                new_snap_key = snap_key(snapshot_ts)\n",
    "                old_snap_key = snap_key(old_snap)\n",
    "\n",
    "                if new_snap_key > old_snap_key:\n",
    "                    batch[stop_id] = new_row\n",
    "                elif new_snap_key == old_snap_key:\n",
    "                    # gleicher Snapshot -> “mehr Info wins” (non-null merge) inkl. cs\n",
    "                    batch[stop_id] = (\n",
    "                        stop_id, old_snap,\n",
    "                        old_aa if old_aa is not None else actual_arrival,\n",
    "                        old_ad if old_ad is not None else actual_departure,\n",
    "                        old_ca if old_ca is not None else cancelled_arrival,\n",
    "                        old_cd if old_cd is not None else cancelled_departure,\n",
    "                        old_ar_cs if old_ar_cs is not None else ar_cs,\n",
    "                        old_dp_cs if old_dp_cs is not None else dp_cs,\n",
    "                    )\n",
    "                # else: älterer Snapshot -> ignorieren\n",
    "\n",
    "            n_s_nodes += 1\n",
    "\n",
    "            if len(batch) >= batch_size:\n",
    "                n_updates += apply_batch(conn, list(batch.values()))\n",
    "                batch.clear()\n",
    "\n",
    "    if batch:\n",
    "        n_updates += apply_batch(conn, list(batch.values()))\n",
    "        batch.clear()\n",
    "\n",
    "    print(\"Done.\")\n",
    "    print(f\"  change files processed: {n_change_files}\")\n",
    "    print(f\"  stop updates staged:    {n_s_nodes}\")\n",
    "    print(f\"  rows updated (SQL):     {n_updates}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) AUSFÜHREN\n",
    "# ----------------------------\n",
    "changes_dir = Path(\"../timetable_changes\")\n",
    "process_change_archives(conn, changes_dir, pattern=\"*.tar.gz\", batch_size=50_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a1f25",
   "metadata": {},
   "source": [
    "Wichtig: ``conn.close()``, ich hatte mal einen Deadlock Error, der ggf. dadurch entstanden ist, dass mehrere Connections aus verschiedenen Notebooks gleichzeitig vorhanden waren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1615aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
